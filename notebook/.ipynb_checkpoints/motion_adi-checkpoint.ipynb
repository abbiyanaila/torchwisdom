{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy import signal\n",
    "from typing import *\n",
    "import os\n",
    "\n",
    "class MotionADI(object):\n",
    "    def __init__(self, thresh = 0.5, limit=10, fdn=30, adi_path=\"result\", **kwargs):\n",
    "        self.fdn = fdn\n",
    "        self.thresh = thresh\n",
    "        self.limit = limit\n",
    "        self.frames: List = []\n",
    "        self.idx = 0\n",
    "        self.motion_idx = []\n",
    "        self.motion_frames = []\n",
    "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        self.is_detected = False\n",
    "        self.detected_id = 0\n",
    "        self.adi_path = adi_path\n",
    "        self.adi_id = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _segmentation(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        op_kernel = np.ones((5, 5), np.uint8)\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, op_kernel)\n",
    "\n",
    "        mean_kernel = np.ones((5, 5), np.uint8) / np.mean(opening)\n",
    "        mean = cv2.filter2D(opening, -1, mean_kernel)\n",
    "\n",
    "        output = mean\n",
    "        return output\n",
    "    \n",
    "    def combine_motion_frame(self):\n",
    "        fshape = self.motion_frames[-1].shape\n",
    "        image = np.zeros(fshape)\n",
    "        for frame in self.motion_frames:\n",
    "            image = np.add(image, frame)\n",
    "        return image\n",
    "    \n",
    "    def filter(self, frame):\n",
    "        seg = self._segmentation(frame)\n",
    "        self.frames.append(seg)\n",
    "        self._put_text(frame, f'Frame Number: {str(self.idx)}', loc=(10,40))\n",
    "        \n",
    "        if len(self.frames) > 0:\n",
    "            abs_diff = cv2.absdiff( self.frames[self.idx - 1], self.frames[self.idx])\n",
    "            motion = np.mean(abs_diff) > self.thresh\n",
    "            if motion:\n",
    "                self.motion_idx.append(self.idx)\n",
    "                if len(self.motion_frames) < self.limit:\n",
    "                    #ngumpulin barang bukti\n",
    "                    self.motion_frames.append(abs_diff)\n",
    "                    return False, abs_diff\n",
    "                else:\n",
    "                    \n",
    "                    # telah lengkap barang bukti\n",
    "                    # motion is detected\n",
    "                    image_adi = self.combine_motion_frame()\n",
    "                    path = os.path.join(self.adi_path, f'frame_{self.adi_id}.jpg')\n",
    "                    cv2.imwrite(path, image_adi)\n",
    "                    self.adi_id +=1\n",
    "                    \n",
    "                    self.motion_frames = []\n",
    "                    self.motion_idx = []\n",
    "                    self.is_detected = True\n",
    "                    self.detected_id = self.idx\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    return True, image_adi\n",
    "            else:\n",
    "                return False, abs_diff\n",
    "        else:\n",
    "            return False, np.zeros(frame.shape)\n",
    "        \n",
    "        \n",
    "    def increment_id(self):\n",
    "        self.idx = self.idx + 1\n",
    "        \n",
    "        \n",
    "    def show_detection(self, frame):\n",
    "        if self.is_detected:\n",
    "            self._put_text(frame, \"Motion: Detected\")\n",
    "            if self.idx-self.detected_id>=self.fdn:\n",
    "                self.is_detected = False\n",
    "                self.detected_id = 0\n",
    "        else: \n",
    "            self._put_text(frame, \"Motion: Undetected\")\n",
    "\n",
    "            \n",
    "    def _put_text(self, frame, text, loc=(10,20)):\n",
    "         cv2.putText(frame, text, loc, self.font, 0.7,(255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-73d6226fa6ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Capture frame-by-frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmot_detect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmadi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmadi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "madi = MotionADI(thresh=0.5, fdn=20)\n",
    "\n",
    "\n",
    "while (True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    mot_detect, output = madi.filter(frame)\n",
    "    madi.show_detection(frame)\n",
    "    madi.increment_id()\n",
    "    \n",
    "    cv2.imshow('motion', output)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
